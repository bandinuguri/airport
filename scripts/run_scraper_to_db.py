import os
import json
import asyncio
import psycopg2
import sys
from urllib.parse import urlparse
from datetime import datetime

# ìƒìœ„ í´ë”ì˜ scraper.pyë¥¼ ì¸ì‹í•˜ê¸° ìœ„í•œ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from scraper import scrape_airport_weather, scrape_special_reports

async def main():
    print(f"ğŸš€ ë°ì´í„° ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ì‹œì‘: {datetime.now()}")

    # 1. ë°ì´í„° ìˆ˜ì§‘
    try:
        weather_task = scrape_airport_weather()
        report_task = scrape_special_reports()
        airport_weather, special_reports = await asyncio.gather(weather_task, report_task)
        print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: ë‚ ì”¨ {len(airport_weather)}ê±´")
    except Exception as e:
        print(f"âŒ ìˆ˜ì§‘ ë‹¨ê³„ ì˜¤ë¥˜: {e}")
        return

    # 2. DB ì—°ê²°
    db_url = os.environ.get("DATABASE_URL")
    if not db_url:
        print("âŒ DATABASE_URL ì—†ìŒ")
        return

    try:
        result = urlparse(db_url)
        conn = psycopg2.connect(
            database=result.path[1:], user=result.username, password=result.password,
            host=result.hostname, port=result.port
        )
        cur = conn.cursor()

        # 3. ë°ì´í„° ì €ì¥
        query = """
            INSERT INTO weather_latest (id, data, special_reports, updated_at)
            VALUES (1, %s, %s, CURRENT_TIMESTAMP)
            ON CONFLICT (id) DO UPDATE 
            SET data = EXCLUDED.data,
                special_reports = EXCLUDED.special_reports,
                updated_at = EXCLUDED.updated_at;
        """
        cur.execute(query, (
            json.dumps(airport_weather, ensure_ascii=False),
            json.dumps(special_reports, ensure_ascii=False)
        ))
        conn.commit()
        print("âœ¨ Supabase ì €ì¥ ì™„ë£Œ!")
    except Exception as e:
        print(f"âŒ DB ì˜¤ë¥˜: {e}")
    finally:
        if 'conn' in locals(): conn.close()

if __name__ == "__main__":
    asyncio.run(main())
